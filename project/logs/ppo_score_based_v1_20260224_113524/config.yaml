checkpoints:
  name_prefix: ppo_score_based
  save_path: logs/checkpoints
  save_replay_buffer: false
  save_vecnormalize: false
deterministic_actions: false
device: auto
environment:
  max_turns: 120
  name: SplendorScoreBased
  opponent: random
  reward_mode: score_progress
evaluation:
  callback_on_eval: false
  deterministic: true
  render: false
experiment:
  name: ppo_score_based_v1
  notes: Initial training run with progress reward mode
  tags:
  - ppo
  - score_based
  - phase1
ppo:
  batch_size: 64
  clip_range: 0.2
  clip_range_vf: null
  ent_coef: 0.01
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.0003
  lr_schedule: constant
  max_grad_norm: 0.5
  n_epochs: 10
  n_steps: 2048
  normalize_advantage: true
  policy: MlpPolicy
  policy_kwargs:
    activation_fn: relu
    net_arch:
    - 256
    - 256
    - 128
  vf_coef: 0.5
seed: 42
training:
  eval_episodes: 10
  eval_freq: 10000
  log_interval: 10
  save_freq: 50000
  tensorboard_log: logs/tensorboard
  total_timesteps: 1000000
  verbose: 1
